{
    "prompt": [{
        "role":"system",
        "content":"The user will ask you a question about the documentation of a python library called DRAG, your task is to answer and resolve the doubts.\nReason step by step:\n1) identify the language of the question, you will have to answer in the same language.\n2) search the text of the DRAG documentation for the parts that may be of interest to you, based on the question.\n3) Generate an answer by rearranging the content of the most interesting parts. Try to provide a complete answer but do not exceed 500 words with your answer. It is very important that you translate everything into the language identified in step 1.\n4) If the user requests it, generate example code based on what you find in the documentation text.\nIt is very important that you only return the answer to the question and not other unnecessary text."          
        },
        {
        "role":"user",
        "content":"DRAG Documentation:'''\nDRAG Documentation\n\n## Introduction\n\nDRAG is a data analysis tool. It allows you to speed up code writing using Large Language Models (LLMs) all using the most popular format in the industry, namely Python notebooks. DRAG is a tool that we like to call noLibrary, since it presents and installs itself in every respect like a Python library, i.e., via pip, but in fact, it is a tool for writing code and more!\n\nDRAG is an advanced RAG system that allows the user to generate new code cells using their preferred LLM. Currently, 7 models are supported, both local and hosted. You can use Llama, Mixtral, and Gemma on Groq; GPT-3.5, GPT-4, GPT-4-o on OpenAI and Azure, but also local models via Ollama. So unlike other copilots, DRAG offers the ability to choose the desired model. Thus, by choosing a local model, you are sure that your data remains safe, making it perfect for analyzing sensitive data.\n\n## Install\n\nDRAG is very easy to install, it is distributed via PyPI and downloadable with pip.\n\n```shell\npip install drag-ai\n```\n\n## Quickstart\n\nGetting started with DRAG is very easy! After installing it on your computer or in your environment, open the Python notebook you need to work on and follow these steps:\n\n1. Import DRAG into your Python notebook\n\n```python\nfrom drag import setup, data, ask\n```\n\n2. Run the 'setup()' method indicating the LLM host you want to use (groq, openai, azure, ollama), the model name (gpt-3.5, llama3, mixtral, gemma, ...) and the key for hosted models or the port for local models.\n\n```python\nsetup({\n\"host\":\"Groq\",\n\"model\":\"llama3-8b-8192\",\n\"api_key\":\"gsk_123ABCdef\"\n})\n```\n\n3. Now you can import data into your notebook to start the analysis. You can write the code yourself or use the 'data()' method that allows you to quickly import various file extensions (csv, json, xls).\n\n```python\ndata(\"your_dataset.csv\")\n```\n\n4. Finally, you can have your code generated by artificial intelligence! Using the 'ask()' method, you can write questions in natural language and the LLM will write the code and add it to your notebook.\n\n```python\nask({\"df\": df}, \"question text ...\")\n```\n\n## Methods\n\n### setup\n\nThe 'setup()' method is used to initialize DRAG and declare the LLM and provider to be used. This method has a dictionary-type parameter. Here's an example of how it is used:\n\n```python\nsetup({\n\"host\":\"Groq\",\n\"model\":\"llama3-8b-8192\",\n\"api_key\":\"gsk_123ABCdef\"\n})\n```\n\nAs shown in the example, in the dictionary under the 'host' key, the provider is indicated as Groq, OpenAI, Azure, Ollama; under the 'model' key, the name of the model to be used is indicated; under the 'api_key' key, the key to make the model work is indicated.\n\n### data\n\nThe 'data()' method allows you to import a dataset easily and quickly regardless of its extension. It takes two input parameters, the second being optional, but both of type string: the first represents the path of the file to be imported while the second the name of the variable to refer to, which by default is 'df'. Currently, files with the extensions: csv, json, xls are supported, but support for other types of files as well as quick connection to SQL and NoSQL databases is under development. Here are two examples of how to use this method:\n\n```python\ndata(\"your_dataset.csv\")\n```\n\n```python\ndata(\"your_dataset.csv\", \"my_dataframe\")\n```\n\n### ask\n\nThe 'ask()' method is the most important method of DRAG, it is the one that allows code generation from natural language text. This method takes two input parameters: a dictionary containing all the dataframes that need to be considered to generate the code; a string representing the user's question. The dictionary has the following form: all keys are strings representing dataframes already declared in the notebook with the same name; while all values are the dataframes themselves. Here is an example to better understand how to use this method:\n\n```python\nask({\"df\": df}, \"question text ...\")\n```\n\n### info\n\nThe 'info()' method allows you to quickly consult the DRAG documentation directly from the notebook you are working on. It is based on a RAG that has this documentation as its knowledge base and an LLM extracts the information you need. This method has only one parameter of type string, which is the user's question about the documentation. It is also possible to request practical examples. Here is an example of how to use this method:\n\n```python\ninfo(\"Explain what DRAG's info method is for\")\n```\n'''\n\n\nAnswer the following question:'''\n%s\n'''"
        }]
}